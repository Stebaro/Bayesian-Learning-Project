---
title: "BayesianCovid"
output:
  html_document: default
  pdf_document: default
date: "2024-01-26"
---

# Data description

```{r}
library(BAS)
library(caret)

# import of dataset
covid.data <- read.csv("covidLom2020_21.csv")

#covid.data
```

## Data Preprocessing

```{r}
# binarization of "color" columns
covid.data$gialla <- as.numeric(covid.data$color == "Gialla")
covid.data$bianca <- as.numeric(covid.data$color == "Bianca")
covid.data$rossa <- as.numeric(covid.data$color == "Rossa")
covid.data$arancione <- as.numeric(covid.data$color == "Arancione")

# elimination of unused columns
covid.data$color<-NULL
covid.data$X<-NULL

```

## Functions

```{r}
# Function to standardize the specific numeric columns
standardize <- function(data, cols) {
  temp.data <- data
  for (col in cols) {
    if (is.numeric(data[[col]])) {
      temp.data[[col]] <- scale(data[[col]])
    }
  }
  temp.data
  return(temp.data)
}

# Function to compute the MSE
mse <- function (model, validation_set, target, estimator) {
  pred_value <- predict(model, validation_set, estimator = estimator)$fit
  true_value <- validation_set[[target]]
  return (mean((true_value - pred_value)^2))
}

# Function used to shuffle the data
# The function uses a seed for reproducibility reason
shuffle <- function(data, seed=NULL) {
  if (!is.null(seed)) {
    set.seed(seed)
  }
  shuffled_indices <- sample(nrow(data))
  shuffled_data <- data[shuffled_indices, ]
  return(shuffled_data)
}

```

# MODEL SPECIFICATION

## Cross validation

```{r}
# standardize and shuffle the data
standardize.columns <- c("newpos", "intcar", "hosp", "newpos_av7D")
shuffled.covid.data<-shuffle(covid.data, 10)
standard.covid.data <- standardize(shuffled.covid.data, standardize.columns)

# Number of folds
k <- 10

# Adding a column with a unique ID for each row
standard.covid.data$unique_id <- row.names(standard.covid.data)

# Index creation
folds <- createFolds(y = standard.covid.data$unique_id, k = k, list = TRUE, returnTrain = FALSE)

# Creation of test and validation set
validation_sets <- list()
training_sets <- list()

for (i in 1:k) {
  # Index of the test and validation set for the i fold
  test_indices <- unlist(folds[i])
  validation_indices <- setdiff(standard.covid.data$unique_id, test_indices)

  # Adding the sets tothe lists
  validation_sets[[i]] <- standard.covid.data[test_indices, ]
  training_sets[[i]] <- standard.covid.data[validation_indices, ]
}

```

## Tuning alpha for HospH8

```{r}

# Create a model using the zellner g-prior and test the mse for different alphas
# Using the training set to create the model and the validation set to calculate the mse
# generated by the prediction

for(alpha in c(0.01,0.1,1,10, 100, 200)){
  # vector used to store the mse of all the folds
  mse.g.prior<-numeric(k)
  # loop cycle to iterate through the folds
  for (i in 1:k){
    modelgprior <- bas.lm(hospH8 ~ gialla + arancione + rossa + newpos + intcar + hosp + newpos_av7D,               
                          data = training_sets[[i]], 
                          alpha= alpha, 
                          prior = "g-prior", 
                          # we only look at one single model that contains all the variables 
                          # except bianca
                          modelprior = Bernoulli(1))
    mse.g.prior[i] <- mse(modelgprior, validation_sets[[i]], "hospH8", "BMA")
  }
  print(paste("Mean MSE for alpha", alpha, "is", mean(mse.g.prior)))
  
}
```

## JZS HospH8

```{r}

# Here we try to use the Zellner-Siow prior instead of the g-prior
# No need for hyperparameter tuning
mse.jzs.prior<-numeric(k)
  for (i in 1:k){
    modelJZS <- bas.lm(hospH8 ~ gialla + arancione + rossa + newpos + intcar + hosp + newpos_av7D, 
                          data = training_sets[[i]], 
                          prior = "JZS", 
                          modelprior = Bernoulli(1))
    
    mse.jzs.prior[i] <- mse(modelJZS, validation_sets[[i]], "hospH8", "BMA")
  }
  print(paste("Mean MSE is", mean(mse.jzs.prior)))
  
```

## BIC HospH8

```{r}

# Here we try to use a non-informative prior using BIC

mse.bic.prior<-numeric(k)
mse.bic.prior1<-numeric(k)
  for (i in 1:k){
    modelBIC <- bas.lm(hospH8 ~ gialla + arancione + rossa + newpos + intcar + hosp + newpos_av7D, 
                          data = training_sets[[i]], 
                          modelprior = Bernoulli(1),
                          prior = "BIC")
    
    mse.bic.prior[i] <- mse(modelBIC, validation_sets[[i]], "hospH8", "BMA")
  }
  print(paste("Mean MSE is", mean(mse.bic.prior)))


```

# MODEL SELECTION

## BIC model for hospH8

```{r}

# To perform model selection we use BIC as before

finalmodelbic=bas.lm(hospH8 ~ gialla + arancione + rossa + newpos + intcar + hosp + newpos_av7D, 
                          data = standard.covid.data, 
                          prior = "BIC", 
                          # This time we are not interested only in the first model so we use
                          # uniform() as our model prior
                          modelprior = uniform())


# show the summary
round(summary(finalmodelbic), 3)

# show the most influent covariates
best=which.max(finalmodelbic$logmarg)
bestmodel=finalmodelbic$which[[best]]+1
bestgamma=rep(0,finalmodelbic$n.vars)
bestgamma[bestmodel]=1
print(bestgamma)

# plots
plot(finalmodelbic, which = 1, ask = FALSE, caption = "", sub.caption = "")
plot(finalmodelbic, which = 4, ask = FALSE, caption = "", sub.caption = "")
```


```{r}

# summary and plots
coefs= coef(finalmodelbic)
coefs

plot(confint(coefs))

par(mfrow=c(2,4))
plot(coefs, ask=F)
out=confint(coefs)[,1:2]
coef.BIC=cbind(coefs$postmean, coefs$postsd, out)
names=c("post mean", "post sd", colnames(out))
colnames(coef.BIC)=names
par(mfrow=c(1,1))
round(coef.BIC, 3)

image(finalmodelbic, rotate=FALSE)

```

```{r}
# Comparison between using the best model or BMA

mse.bic.priorbma<-numeric(k)
mse.bic.priorhpm<-numeric(k)

  for (i in 1:k){
    finalmodelbichospH8 <- bas.lm(hospH8 ~ gialla + arancione + rossa + newpos + intcar + hosp + newpos_av7D, 
                          data = training_sets[[i]], 
                          modelprior = uniform(),
                          prior = "BIC") 

    mse.bic.priorbma[i] <- mse(finalmodelbichospH8, validation_sets[[i]], "hospH8", "BMA")
    mse.bic.priorhpm[i] <- mse(finalmodelbichospH8, validation_sets[[i]], "hospH8", "HPM")
  }

  print(paste("Mean MSE using BMA is", mean(mse.bic.priorbma)))
  print(paste("Mean MSE using HPM is", mean(mse.bic.priorhpm)))
```

### CHECKING OUTLIERS
```{r}
### first the tree outliers found with the residual graph
pred.75=predict(finalmodelbichospH8, newdata=standard.covid.data,  se.fit = TRUE)
out=cbind('75', standard.covid.data[75,]$hospH8)
colnames(out)=c('Point', 'Actual IntcarH8')
print(out)
conf.pred <- confint(pred.75, parm = "pred")
conf.pred[75,]


pred.193=predict(finalmodelbichospH8, newdata=standard.covid.data,  se.fit = TRUE)
out=cbind('184',standard.covid.data[193,]$hospH8)
conf.pred <- confint(pred.193, parm = "pred")
colnames(out)=c('Point', 'Actual IntcarH8')
print(out)
conf.pred[184,]


pred.132=predict(finalmodelbichospH8, newdata=standard.covid.data, se.fit = TRUE)
out=cbind('132',standard.covid.data[132,]$hospH8)
colnames(out)=c('Point', 'Actual IntcarH8')
print(out)
conf.pred <- confint(pred.132, parm = "pred")
conf.pred[132,]

### then one random point to show the predictions are almost correct 
pred.10=predict(finalmodelbichospH8, newdata=standard.covid.data, estimator = "HPM", se.fit = TRUE)
out=cbind('10', standard.covid.data[10,]$hospH8)
colnames(out)=c('Point', 'Actual IntcarH8')
print(out)
conf.pred <- confint(pred.10, parm = "pred")
conf.pred[10,]

```


```{r}
# Creation of two sets for training and prediction
n=40
nend=length(standard.covid.data[,1])
newdata<-standard.covid.data[1:n,]
datalearning<-standard.covid.data[seq(n+1,nend),]
rownames(datalearning)=seq(1:length(datalearning[,1]))
```

### hospH8

```{r}

# Using BIC as prior since it's the best one, and bma as the estimator since
# it gives us the lowest mse

modelbichospH8 <- bas.lm(hospH8 ~ gialla + arancione + rossa + newpos + intcar + hosp + newpos_av7D, 
                          # using the training set
                          data = datalearning, 
                          prior = "BIC", modelprior = uniform())



fitted<-predict(modelbichospH8, estimator = "BMA") # prediciton on the training data
prednew <- predict(modelbichospH8,newdata=newdata, estimator = "BMA") # predictions on new data

# plot that compare the fitted value with the actual one
plot(fitted$Ybma[1:length(fitted$Ybma)],datalearning$hospH8[1:length(fitted$Ybma)],
  pch = 16,
  xlab = expression(hat(mu[i])), ylab = 'Y',type="p", main="Fitted vs Prediction HospH8")

# adding points showing the prediction on new data
points(prednew$Ybma, newdata$hospH8,
  pch = 16,
  col="red",type="p"
)
abline(0,1)

# Calculating predictions and standard errors
BMA <- predict(modelbichospH8, estimator = "BMA", newdata=newdata,se.fit = TRUE)

# Calculating confidence interval for mean and predictions
conf.fit <- confint(BMA, parm = "mean")
conf.pred <- confint(BMA, parm = "pred")
plot(conf.pred, main="Out of sample: pred. (black) vs true (red)")

#adding the true values
points(seq(1:n),newdata$hospH8,col="red")
```


