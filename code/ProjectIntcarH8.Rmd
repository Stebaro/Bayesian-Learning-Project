---
title: "ProjectIntcarH("
output: html_document
date: "2024-02-02"
---

# INTCARH8

# Introduction

```{r}
library(BAS)
library(caret)
```

## Importing the dataset
```{r}
#Showing the first 6 lines of the dataset
covid.data <- read.csv("covidLom2020_21.csv")
```

## Data Processing
```{r}
# Binarization of the 'color' column
covid.data$gialla <- as.numeric(covid.data$color == "Gialla")
covid.data$bianca <- as.numeric(covid.data$color == "Bianca")
covid.data$rossa <- as.numeric(covid.data$color == "Rossa")
covid.data$arancione <- as.numeric(covid.data$color == "Arancione")

# Elimination of unused columns 
covid.data$color<-NULL
covid.data$X<-NULL
```


## Functions
```{r}
# Function to standardize specific numeric columns
standardize <- function(data, cols) {
  temp.data <- data
  for (col in cols) {
    if (is.numeric(data[[col]])) { # Checking if the column is numeric
      # Standardizing the numeric column using the scale function
      temp.data[[col]] <- scale(data[[col]])
    }
  }
  temp.data
  return(temp.data)
}

mse <- function (model, validation_set, target, estimator) {
  
  # Predicting values using the specified model and estimator
  pred_value <- predict(model, validation_set, estimator = estimator)$fit
  true_value <- validation_set[[target]] #true values from the validation set
  return (mean((true_value - pred_value)^2))
}


# Function to shuffle the rows + optional seed for reproducibility
shuffle <- function(data, seed=NULL) {
  if (!is.null(seed)) {
    set.seed(seed)
  }
  shuffled_indices <- sample(nrow(data))
  shuffled_data <- data[shuffled_indices, ]
  return(shuffled_data)
}

```


# MODEL DECISION

## Cross validation

```{r}
standardize.columns <- c("newpos", "intcar", "hosp", "newpos_av7D")
shuffled.covid.data<-shuffle(covid.data, 10)
standard.covid.data <- standardize(shuffled.covid.data, standardize.columns)

# Number of folds
k <- 10

# Adding a columns with a unique ID for each row
standard.covid.data$unique_id <- row.names(standard.covid.data)

# Index creation
folds <- createFolds(y = standard.covid.data$unique_id, k = k, list = TRUE, returnTrain = FALSE)

# Creation of test and validation set
validation_sets <- list()
training_sets <- list()

for (i in 1:k) {
  # Index of the test and validation set for the i fold
  test_indices <- unlist(folds[i])
  validation_indices <- setdiff(standard.covid.data$unique_id, test_indices)

  # Adding the sets tothe lists
  validation_sets[[i]] <- standard.covid.data[test_indices, ]
  training_sets[[i]] <- standard.covid.data[validation_indices, ]
}

```

## Tuning alpha for IntcarH8

```{r}

## Creating a model using the zellner g-prior and test the mse for different alpha
## Using the training set to create the model and the validation set to calculate the mse generated by ## the prediction

for(alpha in c(0.01,0.1,1,10, 100, 200)){
  
  mse.g.prior1<-numeric(k) # vector used to store the mse of all the folds
 
  for (i in 1:k){  # loop to iterate through the folds
    
    # we only look at one single model that contains all the variables except 'bianca'
    modelgpriorintcarH8 <- bas.lm(intcarH8 ~ gialla + arancione + rossa + newpos + intcar + hosp + newpos_av7D, 
                          data = training_sets[[i]], 
                          alpha= alpha, 
                          prior = "g-prior", 
                          modelprior = Bernoulli(1))
    
    mse.g.prior1[i] <- mse(modelgpriorintcarH8, validation_sets[[i]], "intcarH8", "BMA")
  }
  print(paste("Mean MSE for alpha", alpha, "is", mean(mse.g.prior1)))
  
}
```

## JZS IntcarH8

```{r}

## Using the Zellner-Siow prior  (no hyperparameter tuning is needed)
mse.jzs.prior <- numeric(k)

for (i in 1:k) {
  modelJZSintcarH8 <- bas.lm(intcarH8 ~ gialla + arancione + rossa + newpos + intcar + hosp + newpos_av7D, 
                             data = training_sets[[i]], 
                             prior = "JZS", modelprior = Bernoulli(1))
  
  mse.jzs.prior[i] <- mse(modelJZSintcarH8, validation_sets[[i]], "intcarH8", "BMA")
}

print(paste("Mean MSE is", mean(mse.jzs.prior)))

  
```


## BIC IntcarH8

```{r}

## Trying with the non informative prior

mse.bic.prior<-numeric(k)

  for (i in 1:k){
    modelBICintcarH8 <- bas.lm(intcarH8 ~ gialla + arancione + rossa + newpos + intcar + hosp + newpos_av7D, 
                          data = training_sets[[i]], 
                          modelprior = Bernoulli(1),
                          prior = "BIC") 
                          
    mse.bic.prior[i] <- mse(modelBICintcarH8, validation_sets[[i]], "intcarH8", "BMA")
  }

  print(paste("Mean MSE is", mean(mse.bic.prior)))

```


# MODEL SELECTION

## BIC model for INTCARH8

```{r}
#Using BIC to perform model selection

finalmodelbicintcarH8=bas.lm(intcarH8 ~ gialla + arancione + rossa + newpos + intcar + hosp + newpos_av7D, 
                          data = standard.covid.data, 
                          prior = "BIC", modelprior = uniform())

round(summary(finalmodelbicintcarH8), 3)
best=which.max(finalmodelbicintcarH8$logmarg)
bestmodel=finalmodelbicintcarH8$which[[best]]+1
bestgamma=rep(0,finalmodelbicintcarH8$n.vars)
bestgamma[bestmodel]=1
print(bestgamma) #Showing the most important coviariates

## Plots
plot(finalmodelbicintcarH8, which = 1, ask = FALSE, caption = "", sub.caption = "")
plot(finalmodelbicintcarH8, which = 4, ask = FALSE, caption = "", sub.caption = "")
```

```{r}
## Comparison between using the best model (HPM) and MBA
mse.bic.priorbma<-numeric(k)
mse.bic.priorhpm<-numeric(k)

  for (i in 1:k){
    finalmodelbicintcarH8 <- bas.lm(intcarH8 ~ gialla + arancione + rossa + newpos + intcar + hosp + newpos_av7D, 
                          data = training_sets[[i]], 
                          modelprior = uniform(),
                          prior = "BIC") 
                          
    mse.bic.priorbma[i] <- mse(finalmodelbicintcarH8, validation_sets[[i]], "intcarH8", "BMA")
    mse.bic.priorhpm[i] <- mse(finalmodelbicintcarH8, validation_sets[[i]], "intcarH8", "HPM")
  }

  print(paste("Mean MSE using BMA is", mean(mse.bic.priorbma)))
  print(paste("Mean MSE using HPM is", mean(mse.bic.priorhpm)))

```

# Posterior Analysis of the covariates
```{r}
# Summary and plots

coefs= coef(finalmodelbicintcarH8, estimator = "HPM")
coefs

plot(confint(coefs))

par(mfrow=c(2,4))
plot(coefs, ask=F)
out=confint(coefs)[,1:2]
coef.BIC=cbind(coefs$postmean, coefs$postsd, out)
names=c("post mean", "post sd", colnames(out))
colnames(coef.BIC)=names
par(mfrow=c(1,1))
round(coef.BIC, 3)

image(finalmodelbicintcarH8, rotate=FALSE)

```

# Predictive Analysis

```{r}
# Creation of two sets for training and prediction

n=40 #number of elements for the validation set  
nend=length(standard.covid.data[,1])
newdata<-standard.covid.data[1:n,]
datalearning<-standard.covid.data[seq(n+1,nend),]
rownames(datalearning)=seq(1:length(datalearning[,1]))

```


```{r}
## Using BIC as prior since we found is the best one 
## and HPM as estimator since we saw that the model with the highest probability works better than the 
## weighted average of them

modelBICintcarH8 <- bas.lm(intcarH8 ~ gialla + arancione + rossa + newpos + intcar + hosp + newpos_av7D, 
                          data = datalearning, #using the training data
                          prior = "BIC", modelprior = uniform())

fitted<-predict(modelBICintcarH8, estimator = "HPM") #predictions on the training data
prednew <- predict(modelBICintcarH8,newdata=newdata, estimator = "HPM") #predictions on new data


# plot that compares the fitted values with the actual values
plot(fitted$Ypred[1:length(fitted$Ypred)],datalearning$intcarH8[1:length(fitted$Ypred)],
  pch = 16,
  xlab = expression(hat(mu[i])), ylab = 'Y',type="p", main="Fitted vs Prediction HospH8")

# adding points showing the predictions on the new data
points(prednew$Ypred, newdata$intcarH8,
  pch = 16,
  col="red",type="p"
)
abline(0,1)
```

```{r}
# calculating predictions and standard errors
HPM <- predict(modelBICintcarH8, estimator = "HPM", newdata=newdata,se.fit = TRUE)

# calculating confidence interval for mean and predictions
conf.fit <- confint(HPM, parm = "mean")
conf.pred <- confint(HPM, parm = "pred")
plot(conf.pred, main="Out of sample: pred. (black) vs true (red)")

#adding the true values
points(seq(1:n),newdata$intcarH8,col="red")
```


#APPENDIX
## CHECKING OUTLIERS
```{r}
### first the tree outliers found with the residual graph
pred.86=predict(finalmodelbicintcarH8, newdata=standard.covid.data, estimator = "HPM",  se.fit = TRUE)
out=cbind('86', standard.covid.data[86,]$intcarH8)
colnames(out)=c('Point', 'Actual IntcarH8')
print(out)
conf.pred <- confint(pred.86, parm = "pred")
conf.pred[86,]


pred.184=predict(finalmodelbicintcarH8, newdata=standard.covid.data, estimator = "HPM",  se.fit = TRUE)
out=cbind('184',standard.covid.data[184,]$intcarH8)
conf.pred <- confint(pred.184, parm = "pred")
colnames(out)=c('Point', 'Actual IntcarH8')
print(out)
conf.pred[184,]


pred.135=predict(finalmodelbicintcarH8, newdata=standard.covid.data, estimator = "HPM", se.fit = TRUE)
out=cbind('135',standard.covid.data[135,]$intcarH8)
colnames(out)=c('Point', 'Actual IntcarH8')
print(out)
conf.pred <- confint(pred.135, parm = "pred")
conf.pred[135,]

### then one random point to show the predictions are almost correct 
pred.10=predict(finalmodelbicintcarH8, newdata=standard.covid.data, estimator = "HPM", se.fit = TRUE)
out=cbind('10', standard.covid.data[10,]$intcarH8)
colnames(out)=c('Point', 'Actual IntcarH8')
print(out)
conf.pred <- confint(pred.10, parm = "pred")
conf.pred[10,]

```


